{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "263ed68a",
   "metadata": {},
   "source": [
    "\n",
    "### 빵형의 음원추천 알고리즘 정리용 페이지\n",
    " \n",
    " GTZAN dataset : https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification\n",
    " 기반으로 삼은 코드 : https://www.kaggle.com/andradaolteanu/work-w-audio-data-visualise-classify-recommend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a18119",
   "metadata": {},
   "source": [
    "### 데이터셋 다운로드 파트\n",
    "    우리한테는 그렇게까지 필요없다고 생각하는 부분.\n",
    "    why? 직접 받아온 데이터를 기반으로 업데이트 해야하기 때문\n",
    "\n",
    "- 케글과 연동하기\n",
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = '너꺼 케글 아이디'\n",
    "os.environ['KAGGLE_KEY'] = '케글 setting들어가서 token발급 받으면 제공받는 토큰값'\n",
    "\n",
    "- 케글에 제공되어진 폴더 다운로드 받기\n",
    "!kaggle datasets download -d andradaolteanu/gtzan-dataset-music-genre-classification\n",
    "- 다운받은 폴더 압축 풀어주는 로직\n",
    "!unzip -q gtzan-dataset-music-genre-classification.zip\n",
    "\n",
    "** 데이터 폴더 안에 저장된 친구들\n",
    "1. genres_original : 임의로 구성된 10개의 장르별 폴더 -> .wav 웨이브 형태의 음원 파일\n",
    "2. img_original : 동일하게 구성된 10개의 장르별 폴더 - 각 음원들의 멜스펙토그램 사진\n",
    "3. 30초 단위의 오디오 feature 분석한 csv파일\n",
    "4. 3초 단위의 상기 동일한 csv파일\n",
    "\n",
    "일단 다운받아서 확인해보는 것이 좋겠다고 생각이 듭니다~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4568e7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상기 로직 작성해보는 칸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e5951",
   "metadata": {},
   "source": [
    "### 오디오 파일 이해하기!\n",
    "(프로젝트 연관성을 없지만 기본적으로 라이브러리는 설치해야 함)\n",
    "\n",
    "- y: 소리가 떨리는 세기(진폭)를 시간 순서대로 나열한 것\n",
    "- Sampling rate(sr) : 1초당 샘플의 개수, 단위 Hz 도는 kHz\n",
    "\n",
    "librosa 라는 라이브러리를 사용한다는 듯\n",
    "\n",
    "librosa 설치하기\n",
    "    !pip install librosa\n",
    "    import librosa\n",
    "\n",
    "하고 시작해봅시다 우리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b30e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "y, sr = librosa.load('음원파일.wav')\n",
    "\n",
    "print(y)              # 음악을 숫자로 읽어오는 것\n",
    "print(len(y))         # 음악을 숫자로 바꾼 후 길이\n",
    "print('Sampling rate (kHz): %d' % sr)   \n",
    "print('Audio length (seconds): %.2f' % (len(y) / sr))     # 오디오가 몇초 짜리인지 알 수 있는 로직"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c90729",
   "metadata": {},
   "source": [
    "파이썬에서 음악을 들어봅시다.\n",
    "    IPython.display 라는 라이브러리를 통해 가능하다고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a2d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython as ipd\n",
    "\n",
    "ipd.Audio(y, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e66b109",
   "metadata": {},
   "source": [
    "2D 음파 그래프 - pyplot으로 그려집니다.\n",
    "(프로젝트 연관성 거의 없는듯?)\n",
    "\n",
    "필요한 라이브러리\n",
    "matplotlib.pyplot by plt\n",
    "librosa.display\n",
    "가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1746217",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T12:49:37.644491Z",
     "start_time": "2023-02-11T12:49:37.630365Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "plt.figure(figsize=(16,6))         \n",
    "librosa.display.waveplot(y=y, sr=sr)\n",
    "#이 친구를 통해서 그래프를 보여줄 수 있다고 합니다. 가로=시간, y축=오디오 세기\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c81a0",
   "metadata": {},
   "source": [
    "Fourier Transform\n",
    "    - 시간영역 데이터를 주파수 영역으로 변경하는 작업\n",
    "    - y축 : 주파수 (로그 스케일)\n",
    "    - color축 : 데시벨 (진폭)\n",
    "    \n",
    "음원 분석을 보다 용이하게 만드는 작업이라고 합니다.\n",
    "다만 여기서 만들어진 그래프를 보고 이해하기는 많이 어렵다고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d4c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "D = np.abs(librosa.stft(y, n_fft=2048, hop_length=512)) \n",
    "#librosa.stft 를 통해서 변환을 하고 n_fft 는 윈도우 사이즈?? 라고 하네요 ㅎㅎ;;\n",
    "\n",
    "print(D.shape)\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(D)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7492d2af",
   "metadata": {},
   "source": [
    "Spectogram\n",
    "    - 시간에 따른 신호 주파수의 스팩트럼 그래프\n",
    "    - 다른 이름 : Sonographs, Voiceprints, Voicegrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687cb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB = librosa.amplitude_to_db(D, ref=np.max)   # D = 데시벨을 의미.\n",
    "\n",
    "plt.figure(figsize(16,6))\n",
    "librosa.display.specshow(DB, sr=sr, hop_length=512, x_axis='time', y_axis='log')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# 보다 정론된 데이터 그래프가 나오지만 여전히 인간히 알아보기 어렵다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af113939",
   "metadata": {},
   "source": [
    "### Mel Spectogram 만들기\n",
    "Mel Spectogram\n",
    "    (인간이 이해하기 힘든) Spectogram의 y축을 Mel Scale로 변환한 것 (Non-linear transformation)\n",
    "    Mel Scale : https://newsight.tistory.com/294 \n",
    "    주소로 들어가면 음성인식에 관련된 기초에 대해서 알 수 있습니다.\n",
    "    \n",
    "    -> 즉 log 스케일이고 인간이 이해할 수 있는 진폭형 데이터를 보여준다는 의미."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30449536",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = librosa.featire.melspectrogram(y, sr=sr)  # 안되면 melspectogram으로 바꿔주세요.\n",
    "S_DB = librosa.amplitude_to_db(S, ref=np.max)\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "librosa.display.specshow(S_DB, sr=sr, hop_length=512, x_axis='time', y_axis='log')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# 여기서 만들어진 그래프 형태를 가장 많이 쓰인다고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49947488",
   "metadata": {},
   "source": [
    "Ex) 특정 파일 Mel Spectogram 하는 경우\n",
    "    y,sr = librosa.load('불러올 음원 파일 이름.wav')\n",
    "    y, _ = librosa.effects.trim(y)\n",
    "    여기만 다르고 아래는 동일하게 만들어서 Mel Spectogram 만들 수 있다.\n",
    "    S = librosa.featire.melspectrogram(y, sr=sr)\n",
    "    S_DB = librosa.amplitude_to_db(S, ref=np.max)\n",
    "    plt.figure(figsize=(16,6))\n",
    "    librosa.display.specshow(S_DB, sr=sr, hop_length=512, x_axis='time', y_axis='log')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    각각의 음악의 데시벨, 진폭에 따라 다르게 만들어집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1774924f",
   "metadata": {},
   "source": [
    "### 오디오 특성 추출하기 (Audio Feature Extraction)\n",
    "\n",
    "(그렇게까진 필요성이 느껴지지 않는 파트.. 아래 보면 bpm구하는 방법 나와있슴다)\n",
    "\n",
    "- bpm 정보가 없을 때 bpm이 몇인지 예측 할 수가 있습니다~\n",
    "\n",
    "- zero crossing rate 자주 쓰인다고 합니다. 정확한 의미는 무엇일까요;;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd976c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tempo(BPM) 구하는 로직\n",
    "tempo, _ = librosa.beat.beat_track(y, sr=sr)\n",
    "print(tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d30020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero Crossing Rate : 음파가 양에서 음으로 or 음에서 양으로 바뀌는 비율\n",
    "zero_crossings = librosa.zero_crossings(y, pad=False)\n",
    "\n",
    "print(zero_crossings)\n",
    "print(sum(zero_crossings))\n",
    "\n",
    "# 용도에 대해서는 확실히 인지를 못하겠습니다. 특정 기간동안 몇회 crossing이 발생했는지 확인하는 방법\n",
    "n0 = 9000\n",
    "n1 = 9500\n",
    "zero_crossings = librosa.zero_crossings(y[n0:n1], pad=False)\n",
    "print(sum(zero_crossings))\n",
    "# 하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a22b9b",
   "metadata": {},
   "source": [
    "Harmonic and Percussive Components\n",
    "    Harmonics : 사람의 귀로 구분할 수 없는 특징들 (음악의 색깔)\n",
    "    Percussives : 리듬과 감정을 나타내는 충격파"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55132bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_harm, y_perc = librosa.effects.hpss(y)\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(y_harm, color='b')\n",
    "plt.plot(y_perc, color='r')\n",
    "plt.show()\n",
    "\n",
    "# 음악 장르를 구분하는데 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4977da4",
   "metadata": {},
   "source": [
    "Spectral Centroid\n",
    "    - 소리를 주파수 표현했을 떄, 주파수의 가중평균을 계산하여 소리의 \"무게 중심\"이 어딘지를 알려주는 지표\n",
    "    - 예를 들어, 블루스 음악은 무게 중심이 가운데 부분에 놓여있는 반면, 메탈 음악은 (끝 부분에서 달리기 때문에) 노래의 마지막 부분에 무게 중심이 실립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e321b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_controids = librosa.feature.spectral_centroid(y,sr=sr)[0]\n",
    "\n",
    "# Computing the time variable for visualization\n",
    "frames = range(len(spectral_centroids))\n",
    "\n",
    "# Converts frame counts to time (seconds)\n",
    "t = librosa.frames_to_time(frames)\n",
    "\n",
    "import sklearn\n",
    "def normalize(x, axis='0'):\n",
    "    return sklearn.preprocessing.minmax_scale(x, axis=axis)   # preprocessing 전처리 해서 0~1 사이로 나오게 하는 로직\n",
    "\n",
    "plt.figure(figsize(16,6))\n",
    "librosa.display.waveplot(y, sr=sr, alpha=0.5, color='b')\n",
    "plt.plot(t, normalize(spectral_centroids), color='r')\n",
    "plt.show()\n",
    "\n",
    "# 여기서 만들어지는 그래프는 파란색은 본래의 음파 진폭?? 이런것이고\n",
    "# 붉은 색은 음악의 흐름에 따라 어디에 힘이 실리는지 확인 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3803bdbd",
   "metadata": {},
   "source": [
    "Spectral Rolloff\n",
    "    - 신호 모양을 측정\n",
    "    - 총 스펙트럼 에너지 중 낮은 주파수 (85% 이하) 에 얼마나 많이 집중되어 있는가를 확인 가능하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc45d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_rolloff = librosa.reature.spectral_rolloff(y, sr=sr)[0]\n",
    "\n",
    "plt.figure(figsize =(16,6))\n",
    "librosa.display.waveplot(y, sr=sr, alpha=0.5, color='b')\n",
    "plt.plot(t, normalize(spectral_rolloff), color='r')\n",
    "plt.show()\n",
    "\n",
    "# 위 그래프와 비슷하게 나타나고 이것도 자주 참조가 된다고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a578f315",
   "metadata": {},
   "source": [
    "### Mel-Frequency Cepstral Coefficients(MFCCs)\n",
    "\n",
    "가장 중요한 특징이라고 합니다.\n",
    "\n",
    "MFCCs는 특징들의 작은 집합(약 10~20)으로 스펙트럴 포곡선의 전체적인 모양을 축약해서 보여준다\n",
    "사람의 청각 구조를 반영하여 음성 정보 추출\n",
    "https://tech.kakaoenterprise.com/66\n",
    "\n",
    "이것을 통해 ai에게 학습을 시켜주는 듯 싶습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4fd40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = librosa.feature.mfcc(y, sr=sr)\n",
    "mfccs = normalize(mfccs, axis=1)\n",
    "\n",
    "print('mean: %.2f' % mfccs.mean())   # mfcc의 평균값\n",
    "print('var: %.2f' % mfccs.var())   # mfcc의 분산값\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93916c4f",
   "metadata": {},
   "source": [
    "Chroma Frequencies\n",
    "    - 크로마 특징은 음악의 흥미롭고 강렬한 표현\n",
    "    - 크로마는 인간 청각이 옥파브 차이가 나는 주파수를 가진 두 음을 유사음으로 인지한다는 음악이론에 기반\n",
    "    - 모든 스펙트럼을 12개의 Bin으로 표현\n",
    "    - 2개의 Bin은 옥타브에서 12개의 각기 다른 반응(Semitones = Chroma)을 의미한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c8ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromagram = librosa.feature.chroma_stft(y, sr=sr, hop_length=512)\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', hop_length=512)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ffdf7",
   "metadata": {},
   "source": [
    "#### 기도 메타\n",
    "- 이거 만든 사람도 알아서 잘 분류하겠지? 하는 마인드로 만들었다고 합니다... 매우 어렵네요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8ce9a4",
   "metadata": {},
   "source": [
    "### 학습\n",
    "#### 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf0c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Data/features_3_sec.csv')  # gtzan 데이터 받으면 포함되어있는 데이터\n",
    "\n",
    "df.head() # 뭐가 있는가 봐봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69b05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  전처리를 해보아요\n",
    "\n",
    "x = df.drop(columns =['filename','length','label'])\n",
    "# 여기서 label은 장르를 의미. \n",
    "y = df['label']\n",
    "# 분석해서 label 즉 장르를 알아내는 작업을 할 계획\n",
    "\n",
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "np_scaled = scaler.fit_tramsform(%)\n",
    "\n",
    "X = pd.DataFrame(np_scaled, columns=X.columns)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c3c2c",
   "metadata": {},
   "source": [
    "### 데이터셋 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6592ef4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T15:40:09.407880Z",
     "start_time": "2023-02-11T15:40:09.401896Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2, random_state=2021)\n",
    "# 트레인 셋은 80%, 테스트 셋은 20%만 쓴다는 말이라는데요..?\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)\n",
    "# 데이터의 갯수를 출력하는 곳"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3c60b7",
   "metadata": {},
   "source": [
    "#### 학습 및 검증\n",
    "- xgboost는 설치해야하는 라이브러리라서 anaconda prompt 에\n",
    "- pip install xgboost 입력하고 enter 누르면 설치가 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "595bd52d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T15:43:33.441667Z",
     "start_time": "2023-02-11T15:43:32.973589Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# xgboost 가 성능이 아주 좋다고 합니다.\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=1000, learning_rate=0.05)\n",
    "xgb.fit(X_train, Y_train)\n",
    "# 학습을 시작하게 하는 .fit()\n",
    "\n",
    "Y_preds = xgb.predict(X_test)\n",
    "# 검증할 때 쓰는 .predict() 메소드 ... 결과값 넣기\n",
    "\n",
    "print('Acuuracy: %.2f' % acciracy_score(Y_test,Y_preds))\n",
    "# 정답값과 예측 값에 대해 출력하게 하는 로직. 정확도에 대한 값이 출력된다는 듯?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50397559",
   "metadata": {},
   "source": [
    "#### Confusion Matrix 그려보기\n",
    "- 그리게 되면 가로측이 우리가 예측한 값\n",
    "- 세로측이 정답값이 나오게 됩니다.\n",
    "- 오답의 경우가 몇개 나오는데 bpm이나 이런걸로 다른 친구로 예측하는 경우가 있긴한데\n",
    "- 높은 확률로 동일한 결과가 나오는 걸 확인가능하다. ( ai의 정확성에 대해서 파악할 때 쓰는듯?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de3c004c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T15:49:28.792098Z",
     "start_time": "2023-02-11T15:49:28.603292Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns   # 얘는 내장라이브러리 인듯\n",
    "\n",
    "cm = comfusion_matrix(Y_test, Y_preds)\n",
    "\n",
    "plt.figure(figsize(16,9))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    xticklabel=[\"blues\",\"classical\",\"country\",\"disco\",\"hiphop\",\"jazz\",\"metal\",\"pop\",\"reggae\",\"rock\"]\n",
    "    yticklabel=[\"blues\",\"classical\",\"country\",\"disco\",\"hiphop\",\"jazz\",\"metal\",\"pop\",\"reggae\",\"rock\"]\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cb053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature, importance in zip(X_test.columns, xgb.feature_importances_):\n",
    "    print('%s: %.2f' % (feature, impotance))\n",
    "\n",
    "# feature, importance 개념 : 어떤 feature가 가장 중요한지를 알려주는 메소드?? 같은 아이.\n",
    "# 특징에 따른 중요도를 알려주는데 특히 가장 중요한 점이 무엇인지 알려주는 것. 솔직히 쓸 일 없을듯;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a85c75",
   "metadata": {},
   "source": [
    "### 빵형 유튭에서 알려주는 간단한 추천 시스템\n",
    "- 코사인 유사도를 통해서 알려주는 듯합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bbfde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30 = pd.read_scv('Data/features_30_sec.csv', index_col='filename')\n",
    "# 다운받은 폴더에서 불러오고.\n",
    "\n",
    "labels = df_30[['label']]\n",
    "df_30 = df_30.drop(columns=['length','label'])\n",
    "# 둘은 빠져야 함. -> 오디오의 feature만을 사용해서 추천한다는 가정하에\n",
    "# 그렇다면 이런식으로 다 가야하나??? feature만 알아내는?\n",
    "# 우리가 받아오는 음원에는 feature가 다 들어있는가? 음원 파일식으로 어떻게 받아오는가\n",
    "\n",
    "df_30_scaled = sklearn.preprocesiing.scale(df_30)\n",
    "\n",
    "df_30 = pd.DataFrame(df_30_scaled, columns=df_30.columns)\n",
    "\n",
    "df_30.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faeb3ec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T16:02:16.253469Z",
     "start_time": "2023-02-11T16:02:16.241500Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity # 얘도 바로 import 가능\n",
    "\n",
    "similarity = cosine_similarity(df_30)\n",
    "# 전처리한 데이터만 넣어주면 알아서 처리해준다.\n",
    "\n",
    "sim_df = pd.DataFrame(similarity, index=labels.index, columns=labels.index)\n",
    "# 가로 세로가 전부 음악을 index한 곡들이 나오고 각 곡들 별로 코사인 유사도를 알려주게 됩니다.\n",
    "# 상당히 신기합니다. 해보세요 심심할 때\n",
    "\n",
    "sim_df.head()\n",
    "\n",
    "# 이부분은 코사인 유사도를 통해 백터값을 알아내고 백터값이 1에 가까울수록 비슷한 음악임을\n",
    "# -1에 가까울 수록 전혀 다른 음악임을 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fece800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_similar_songs 함수 정의하기!\n",
    "def find_similar_songs(name, n=5):\n",
    "    series = sim_df[name].sort_values(ascending=False)\n",
    "    \n",
    "    series = series.drop(name)\n",
    "    \n",
    "    return series.head(n).to_frame()\n",
    "    # 매개변수에 들어갈 친구와 가장 비슷한 노래 5곡을 추천해 달라는 함수\n",
    "    # 여기서 n은 강사님들한테 받은 top_n 이랑 같은 부분이고 name에는 저장된 곡명을 넣으면 된다.\n",
    "    \n",
    "find_similar_songs('rock.0000.wav')\n",
    "# rock.0000 이라는 음원파일과 가장 유사도가 높은 곡 5개를 추천해달라! 는 의미\n",
    "# 거의다 같은 장르가 출력되지만 한번씩 비슷한 느낌의 다른 장르의 곡이 출력되기도 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4d5270",
   "metadata": {},
   "source": [
    "### 그래서 어떻게?\n",
    "#### 이걸 어떻게 대입할지 고민해봐야 하는 데  문제점이 있습니다.\n",
    "#### 음악파일 (재생이 가능한) 친구를 바탕으로 feature를 추출해서 그 feature를 바탕으로 코사인 유사도를 찾는 작업을 반복하는 것인데 음원파일을 어떻게 받아오는가? \n",
    "#### 크롤링해서 받아오는 것이 음원파일을 대체할 수 있는가?\n",
    "#### 일단 가서 데이터 다운받아서 폴더별 음원파일에 특징을 아라보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e436e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
